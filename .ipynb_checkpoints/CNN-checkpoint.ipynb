{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52622442-ee01-4f79-ad0a-ba6efe8fb2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training device in use: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ff478174c70>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from random import sample\n",
    "from nn_tools import *\n",
    "from itertools import product as prod\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler as rand_sampler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Training device in use: {device}\")\n",
    "\n",
    "seed = 69420\n",
    "\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acc8764-8917-4587-8c48-dbef5c846ea6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6d4c107-d848-489f-bf8f-7c92e3faaa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6edae38-a626-486f-9f88-cd5f262e9f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor()]) \n",
    "\n",
    "train_dataset = datasets.FashionMNIST('classifier_data', train=True, download=True, transform = transform)\n",
    "test_dataset  = datasets.FashionMNIST('classifier_data', train=False, download=True, transform = transform)\n",
    "\n",
    "n_train = int(len(train_dataset)/2)\n",
    "n_test = int(len(test_dataset))\n",
    "\n",
    "split_idx = int(0.75*n_train)\n",
    "train_samples = rand_sampler(list(range(n_train))[:split_idx])\n",
    "val_samples = rand_sampler(list(range(n_train))[split_idx:])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, sampler = train_samples, batch_size = 256, num_workers = 0)\n",
    "val_dataloader = DataLoader(train_dataset, sampler = val_samples, batch_size = n_train - split_idx, num_workers = 0)\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size = None, shuffle = True, num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63cea045-1322-481d-bc24-d77196f6135f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataloader.dataset.data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5973d0ec-e9a7-45bd-be5e-1d8248e375fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAMPLE AT INDEX 37\n",
      "LABEL: 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_index = 37\n",
    "image = train_dataset[sample_index][0].squeeze()\n",
    "label = train_dataset[sample_index][1]\n",
    "\n",
    "fig = plt.figure(figsize=(2,2))\n",
    "plt.imshow(image, cmap='Greys')\n",
    "print(f\"SAMPLE AT INDEX {sample_index}\")\n",
    "print(f\"LABEL: {label}\")\n",
    "\n",
    "img_shape = tuple(image.shape)\n",
    "no_labels = len(np.unique(train_dataset.train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd4757e6-2545-430a-a5ef-7af299be0c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN2D(data_API):\n",
    "    \n",
    "    def __init__(self, device, in_side, conv1_filters, k_size1, conv2_filters, k_size2, Nh1, Nh2, N_labels):\n",
    "        \"\"\"\n",
    "        Ni - Input size\n",
    "        Nh1 - Neurons in the 1st hidden layer\n",
    "        Nh2 - Neurons in the 2nd hidden layer\n",
    "        No - Output size\n",
    "        \"\"\"\n",
    "        super().__init__(device)\n",
    "        super().train_model\n",
    "        self.conv1 = nn.Conv2d(1, conv1_filters, k_size1) # 28 to 24(* conv1_size)\n",
    "        self.conv2 = nn.Conv2d(conv1_filters, conv2_filters, k_size2) # 24 to 12, and 12 to 8(*conv2_size)\n",
    "        self.conv_shape = self.no_params_conv(self.no_params_conv(self.no_params_conv(self.no_params_conv(in_side, k_size1, 0, 1), 2, 0, 1), k_size2, 0, 1), 2, 0, 1)\n",
    "        self.fc1 = nn.Linear(in_features= conv2_filters*self.conv_shape**2, out_features=Nh1)\n",
    "        self.dropout = nn.Dropout(p = 0.4)\n",
    "        self.fc2 = nn.Linear(in_features=Nh1, out_features=Nh2)\n",
    "        self.out = nn.Linear(in_features=Nh2, out_features=N_labels)\n",
    "                \n",
    "        print(\"Network initialized\")\n",
    "        \n",
    "    def forward(self, x, additional_out=False):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2, stride = 1)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2, stride = 1)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n",
    "    def no_params_conv(self, in_size, kernel, padding, stride):\n",
    "        \"\"\"\n",
    "        Finds no of parameters per channel after every convolution/pooling\n",
    "        \"\"\"\n",
    "        return int((in_size - kernel + 2*padding)/stride + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb00af29-3eaa-4dfb-b63c-9ca9adfd0609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network initialized\n"
     ]
    }
   ],
   "source": [
    "fashion_classifier = CNN2D(device, 28, 5, 4, 8, 3, 20, 16, no_labels)\n",
    "\n",
    "fashion_classifier.to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(fashion_classifier.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac0f8f12-c5f8-44d8-908b-05080cf7f781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 49 :::::::::: AVERAGE VAL LOSS: 0.41606\r"
     ]
    }
   ],
   "source": [
    "fashion_classifier.train_model(train_dataloader, 50, loss_fn, optimizer, val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce2dc46-f7e9-4f83-9f0e-fff8e9c57e61",
   "metadata": {},
   "source": [
    "For ease, I'll normalize the pixel values of the data from (0,255) to (0,1)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-9.m82",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-9:m82"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
